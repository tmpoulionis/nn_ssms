{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b75c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/tmpoulionis/miniconda3/envs/mamba/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from models.test_model import MambaModel\n",
    "from utils.lightning import LightningMamba\n",
    "from experiments.sc09_class import get_config\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from utils.utils import set_seed, model_summary, format_time, handle_wandb_login\n",
    "import wandb\n",
    "import time\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873c46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Set seed for reproducibility\n",
    "if config[\"seed\"]:\n",
    "    set_seed(config[\"seed\"])\n",
    "\n",
    "# Parse config\n",
    "MODEL_CONFIG = config[\"model\"]\n",
    "TRAINER_CONFIG = config[\"trainer\"]\n",
    "DATASET_CONFIG = config[\"dataset\"]\n",
    "OPTIMIZER_CONFIG = config[\"optimizer\"]\n",
    "WANDB_CONFIG = config[\"wandb\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98c6f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Loading sc09 dataset...\n",
      "\t Creating DataLoaders...\n",
      "\t Dataloaders created.\n",
      "  ✓ Dataset: sc09\n",
      "  ✓ Classes: 10\n",
      "  ✓ Input shape: torch.Size([128, 107, 64])\n",
      "  ✓ Features: 64\n",
      "  ✓ Sequence Length: 107\n"
     ]
    }
   ],
   "source": [
    "# ------- Load Dataset and create DataLoaders -------\n",
    "data = data.get_dataloaders(**DATASET_CONFIG)\n",
    "train_loader = data[\"train_loader\"]\n",
    "val_loader = data[\"val_loader\"]\n",
    "test_loader = data[\"test_loader\"]\n",
    "num_classes = data[\"num_classes\"]\n",
    "if TRAINER_CONFIG[\"max_epochs\"] is not None:\n",
    "    total_steps = len(train_loader) * TRAINER_CONFIG[\"max_epochs\"]\n",
    "    if TRAINER_CONFIG[\"max_steps\"] is not None:\n",
    "        total_steps = min(total_steps, TRAINER_CONFIG[\"max_steps\"])\n",
    "else:\n",
    "    try:\n",
    "        total_steps = TRAINER_CONFIG[\"max_steps\"]\n",
    "    except: \n",
    "        raise ValueError(\"Either max_steps or max_epochs must be defined.\")\n",
    "    \n",
    "print(f\"  ✓ Dataset: {DATASET_CONFIG['dataset_name']}\")\n",
    "print(f\"  ✓ Classes: {data['num_classes']}\")\n",
    "print(f\"  ✓ Input shape: {data['input_shape']}\")\n",
    "print(f\"  ✓ Features: {data['feature_dim']}\")\n",
    "print(f\"  ✓ Sequence Length: {data['sequence_length']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f704894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MambaModel                               --\n",
       "├─ModuleList: 1-1                        --\n",
       "│    └─PhotonicMamba: 2-1                --\n",
       "│    │    └─Mamba: 3-1                   32,640\n",
       "├─ModuleList: 1-2                        --\n",
       "│    └─LayerNorm: 2-2                    128\n",
       "├─LayerNorm: 1-3                         128\n",
       "├─Sequential: 1-4                        --\n",
       "│    └─Linear: 2-3                       8,320\n",
       "│    └─LayerNorm: 2-4                    256\n",
       "│    └─GELU: 2-5                         --\n",
       "│    └─Dropout: 2-6                      --\n",
       "│    └─Linear: 2-7                       1,290\n",
       "=================================================================\n",
       "Total params: 42,762\n",
       "Trainable params: 42,762\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------- Create Model -------\n",
    "print(\"Constructing Model...\")\n",
    "model = MambaModel(**MODEL_CONFIG, d_out=num_classes).cuda()\n",
    "model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0b9de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/6] Setting up W&B Logger...\n",
      "\n",
      "--- Weights & Biases (W&B) Configuration ---\n",
      "W&B username: tmpoulionis-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtmpoulionis\u001b[0m (\u001b[33mtmpoulionis-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B login successful!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb_logs/wandb/run-20251120_135441-n7xq75va</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tmpoulionis-/lightning_logs/runs/n7xq75va' target=\"_blank\">splendid-silence-44</a></strong> to <a href='https://wandb.ai/tmpoulionis-/lightning_logs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tmpoulionis-/lightning_logs' target=\"_blank\">https://wandb.ai/tmpoulionis-/lightning_logs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tmpoulionis-/lightning_logs/runs/n7xq75va' target=\"_blank\">https://wandb.ai/tmpoulionis-/lightning_logs/runs/n7xq75va</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Project: lightning_logs\n",
      "  ✓ Name: splendid-silence-44\n",
      "  ✓ URL: https://wandb.ai/tmpoulionis-/lightning_logs/runs/n7xq75va\n"
     ]
    }
   ],
   "source": [
    "# ------- W&B Logger -------\n",
    "print(\"\\n[3/6] Setting up W&B Logger...\")\n",
    "usrname = handle_wandb_login()\n",
    "wandb_logger = WandbLogger(\n",
    "    project=WANDB_CONFIG[\"project\"],\n",
    "    entity=usrname,\n",
    "    name=WANDB_CONFIG[\"name\"],\n",
    "    log_model=\"all\",\n",
    "    save_dir=\"./wandb_logs\"\n",
    ")\n",
    "\n",
    "print(f\"  ✓ Project:\", wandb_logger.experiment.project)\n",
    "print(f\"  ✓ Name:\", wandb_logger.experiment.name)\n",
    "print(f\"  ✓ URL:\", wandb_logger.experiment.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a51c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/6] Setting up Callbacks...\n",
      "  ✓ Learning rate monitor\n",
      "  ✓ Model checkpointing (save top 3)\n",
      "  ✓ Early stopping (patience=20)\n"
     ]
    }
   ],
   "source": [
    "# ------- Callbacks -------\n",
    "print(\"\\n[4/6] Setting up Callbacks...\")\n",
    "\n",
    "callbacks = [\n",
    "    LearningRateMonitor(logging_interval='step'),\n",
    "    ModelCheckpoint(\n",
    "        dirpath=f\"./checkpoints/{wandb_logger.name}\",\n",
    "        filename=\"best-{epoch:02d}-{val/acc:.4f}\",\n",
    "        monitor=\"val/acc\",\n",
    "        mode=\"max\",\n",
    "        save_top_k=1,\n",
    "        save_last=True\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val/loss\",\n",
    "        patience=20,\n",
    "        mode=\"min\",\n",
    "        verbose=True\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"  ✓ Learning rate monitor\")\n",
    "print(f\"  ✓ Model checkpointing (save top 3)\")\n",
    "print(f\"  ✓ Early stopping (patience=20)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca97fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Scheduler -------\n",
    "from train import create_scheduler\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "scheduler_config = {\n",
    "    \"scheduler\": create_scheduler,\n",
    "    \"params\": {\n",
    "        \"total_steps\": total_steps,\n",
    "        \"warmup_steps\": warmup_steps\n",
    "    }\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf18a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/6) Setting up Lightning Module...\n"
     ]
    }
   ],
   "source": [
    "# ------- Lightning Module -------\n",
    "print(\"\\n[5/6) Setting up Lightning Module...\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "lightning_module = LightningMamba(\n",
    "    model=model,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    loss_fn=loss_fn,\n",
    "    opt_hyperparams=OPTIMIZER_CONFIG,\n",
    "    scheduler_config=scheduler_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72506922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/6] Initializing Trainer...\n",
      "  ✓ Max steps: 200000\n",
      "  ✓ Max epochs: 30\n",
      "  ✓ Accelerator: auto\n",
      "  ✓ Gradient clip: 0.1\n"
     ]
    }
   ],
   "source": [
    "# ------- Trainer -------\n",
    "print(\"\\n[6/6] Initializing Trainer...\")\n",
    "trainer = L.Trainer(\n",
    "    **TRAINER_CONFIG,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "print(f\"  ✓ Max steps: {TRAINER_CONFIG['max_steps'] if TRAINER_CONFIG['max_steps'] else 'N/A'}\")\n",
    "print(f\"  ✓ Max epochs: {TRAINER_CONFIG['max_epochs'] if TRAINER_CONFIG['max_epochs'] else 'N/A'}\")\n",
    "print(f\"  ✓ Accelerator: {TRAINER_CONFIG['accelerator']}\")\n",
    "print(f\"  ✓ Gradient clip: {TRAINER_CONFIG['gradient_clip_val']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c509ddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/tmpoulionis/miniconda3/envs/mamba/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataloaders.data import get_dataloaders\n",
    "data = get_dataloaders(\"sc09\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7ba341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loader': <torch.utils.data.dataloader.DataLoader at 0x7fbee55f3490>,\n",
       " 'valid_loader': <torch.utils.data.dataloader.DataLoader at 0x7fbee55f3040>,\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x7fbee55f3100>,\n",
       " 'input_shape': [32, 131071],\n",
       " 'num_classes': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36607f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974\n",
      "114\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "print(len(data['train_loader']))\n",
    "print(len(data['valid_loader']))\n",
    "print(len(data['test_loader']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a79803",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(data['train_loader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8865592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a342b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-0.1071, -0.1168, -0.1457,  ..., -0.1460, -0.1460, -0.1460],\n",
       "          [-0.0752, -0.0927, -0.1454,  ..., -0.1460, -0.1461, -0.1461],\n",
       "          [-0.0830, -0.0986, -0.1455,  ..., -0.1460, -0.1461, -0.1461],\n",
       "          ...,\n",
       "          [-0.1236, -0.1289, -0.1450,  ..., -0.1458, -0.1460, -0.1461],\n",
       "          [-0.1365, -0.1386, -0.1452,  ..., -0.1460, -0.1461, -0.1461],\n",
       "          [-0.1194, -0.1257, -0.1444,  ..., -0.1460, -0.1460, -0.1460]],\n",
       " \n",
       "         [[-0.1490, -0.1486, -0.1475,  ..., -0.1492, -0.1492, -0.1492],\n",
       "          [-0.1467, -0.1470, -0.1480,  ..., -0.1492, -0.1492, -0.1492],\n",
       "          [-0.1478, -0.1479, -0.1482,  ..., -0.1492, -0.1492, -0.1492],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.0618, -0.0618, -0.0618,  ..., -0.0618, -0.0618, -0.0618],\n",
       "          [-0.0611, -0.0612, -0.0615,  ..., -0.0618, -0.0618, -0.0618],\n",
       "          [-0.0616, -0.0616, -0.0618,  ..., -0.0617, -0.0617, -0.0618],\n",
       "          ...,\n",
       "          [-0.0132,  0.0455,  0.2017,  ..., -0.0617, -0.0617, -0.0618],\n",
       "          [-0.0177,  0.0296,  0.1550,  ..., -0.0617, -0.0617, -0.0618],\n",
       "          [ 0.1102,  0.2983,  0.7973,  ..., -0.0617, -0.0617, -0.0617]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.1177, -0.1177, -0.1177,  ..., -0.1177, -0.1177, -0.1177],\n",
       "          [-0.1177, -0.1177, -0.1177,  ..., -0.1177, -0.1177, -0.1177],\n",
       "          [-0.1177, -0.1177, -0.1177,  ..., -0.1177, -0.1177, -0.1177],\n",
       "          ...,\n",
       "          [-0.1177, -0.1177, -0.1177,  ..., -0.0930, -0.1142, -0.1166],\n",
       "          [-0.1177, -0.1177, -0.1177,  ..., -0.0277, -0.0798, -0.1152],\n",
       "          [-0.1177, -0.1175, -0.1171,  ..., -0.0904, -0.1028, -0.1145]],\n",
       " \n",
       "         [[-0.1320, -0.1320, -0.1320,  ..., -0.1320, -0.1320, -0.1320],\n",
       "          [-0.1320, -0.1320, -0.1320,  ..., -0.1320, -0.1320, -0.1320],\n",
       "          [-0.1320, -0.1320, -0.1320,  ..., -0.1320, -0.1320, -0.1320],\n",
       "          ...,\n",
       "          [-0.1320, -0.1320, -0.1320,  ..., -0.1320, -0.1320, -0.1320],\n",
       "          [-0.1320, -0.1320, -0.1320,  ..., -0.1320, -0.1320, -0.1320],\n",
       "          [-0.1320, -0.1320, -0.1320,  ..., -0.1320, -0.1320, -0.1320]],\n",
       " \n",
       "         [[-0.1240, -0.1240, -0.1240,  ..., -0.1240, -0.1240, -0.1240],\n",
       "          [-0.1240, -0.1240, -0.1240,  ..., -0.1240, -0.1240, -0.1240],\n",
       "          [-0.1240, -0.1240, -0.1240,  ..., -0.1240, -0.1240, -0.1240],\n",
       "          ...,\n",
       "          [-0.1240, -0.1240, -0.1240,  ..., -0.1240, -0.1240, -0.1240],\n",
       "          [-0.1240, -0.1240, -0.1240,  ..., -0.1240, -0.1240, -0.1240],\n",
       "          [-0.1240, -0.1240, -0.1240,  ..., -0.1240, -0.1240, -0.1240]]]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46fbc928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1071, -0.1168, -0.1457,  ..., -0.1460, -0.1460, -0.1460],\n",
       "        [-0.0752, -0.0927, -0.1454,  ..., -0.1460, -0.1461, -0.1461],\n",
       "        [-0.0830, -0.0986, -0.1455,  ..., -0.1460, -0.1461, -0.1461],\n",
       "        ...,\n",
       "        [-0.1236, -0.1289, -0.1450,  ..., -0.1458, -0.1460, -0.1461],\n",
       "        [-0.1365, -0.1386, -0.1452,  ..., -0.1460, -0.1461, -0.1461],\n",
       "        [-0.1194, -0.1257, -0.1444,  ..., -0.1460, -0.1460, -0.1460]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c71d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import load_config\n",
    "from dataloaders.data import get_dataloaders, create_dataset\n",
    "config = load_config('hg38_gene')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bf8103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = config[\"dataset\"]\n",
    "data, _ = create_dataset('hg38')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4b43a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f1b28f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max token index in dataset: 11\n",
      "Min token index in dataset: 7\n"
     ]
    }
   ],
   "source": [
    "max_token = -float('inf')\n",
    "min_token = float('inf')\n",
    "\n",
    "for x, y in dataset:\n",
    "    max_token = max(max_token, x.max().item())\n",
    "    min_token = min(min_token, x.min().item())\n",
    "\n",
    "print(\"Max token index in dataset:\", max_token)\n",
    "print(\"Min token index in dataset:\", min_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ec0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "datater = iter(data['train_loader'])\n",
    "sample = next(datater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cacae146",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "278cc4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8506"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['train_loader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eab79f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10) tensor(7)\n"
     ]
    }
   ],
   "source": [
    "print(x.max(), x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279ac328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
