{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5b75c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/tmpoulionis/miniconda3/envs/mamba/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from models.test_model import MambaModel\n",
    "from utils.lightning import LightningMamba\n",
    "from config import get_config\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from utils.utils import set_seed, model_summary, format_time, handle_wandb_login\n",
    "import wandb\n",
    "import time\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873c46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Set seed for reproducibility\n",
    "if config[\"seed\"]:\n",
    "    set_seed(config[\"seed\"])\n",
    "\n",
    "# Parse config\n",
    "MODEL_CONFIG = config[\"model\"]\n",
    "TRAINER_CONFIG = config[\"trainer\"]\n",
    "DATASET_CONFIG = config[\"dataset\"]\n",
    "OPTIMIZER_CONFIG = config[\"optimizer\"]\n",
    "WANDB_CONFIG = config[\"wandb\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98c6f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Loading sc09 dataset...\n",
      "\t Creating DataLoaders...\n",
      "\t Dataloaders created.\n",
      "  ✓ Dataset: sc09\n",
      "  ✓ Classes: 10\n",
      "  ✓ Input shape: torch.Size([128, 107, 64])\n",
      "  ✓ Features: 64\n",
      "  ✓ Sequence Length: 107\n"
     ]
    }
   ],
   "source": [
    "# ------- Load Dataset and create DataLoaders -------\n",
    "data = data.get_dataloaders(**DATASET_CONFIG)\n",
    "train_loader = data[\"train_loader\"]\n",
    "val_loader = data[\"val_loader\"]\n",
    "test_loader = data[\"test_loader\"]\n",
    "num_classes = data[\"num_classes\"]\n",
    "if TRAINER_CONFIG[\"max_epochs\"] is not None:\n",
    "    total_steps = len(train_loader) * TRAINER_CONFIG[\"max_epochs\"]\n",
    "    if TRAINER_CONFIG[\"max_steps\"] is not None:\n",
    "        total_steps = min(total_steps, TRAINER_CONFIG[\"max_steps\"])\n",
    "else:\n",
    "    try:\n",
    "        total_steps = TRAINER_CONFIG[\"max_steps\"]\n",
    "    except: \n",
    "        raise ValueError(\"Either max_steps or max_epochs must be defined.\")\n",
    "    \n",
    "print(f\"  ✓ Dataset: {DATASET_CONFIG['dataset_name']}\")\n",
    "print(f\"  ✓ Classes: {data['num_classes']}\")\n",
    "print(f\"  ✓ Input shape: {data['input_shape']}\")\n",
    "print(f\"  ✓ Features: {data['feature_dim']}\")\n",
    "print(f\"  ✓ Sequence Length: {data['sequence_length']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f704894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MambaModel                               --\n",
       "├─ModuleList: 1-1                        --\n",
       "│    └─PhotonicMamba: 2-1                --\n",
       "│    │    └─Mamba: 3-1                   32,640\n",
       "├─ModuleList: 1-2                        --\n",
       "│    └─LayerNorm: 2-2                    128\n",
       "├─LayerNorm: 1-3                         128\n",
       "├─Sequential: 1-4                        --\n",
       "│    └─Linear: 2-3                       8,320\n",
       "│    └─LayerNorm: 2-4                    256\n",
       "│    └─GELU: 2-5                         --\n",
       "│    └─Dropout: 2-6                      --\n",
       "│    └─Linear: 2-7                       1,290\n",
       "=================================================================\n",
       "Total params: 42,762\n",
       "Trainable params: 42,762\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------- Create Model -------\n",
    "print(\"Constructing Model...\")\n",
    "model = MambaModel(**MODEL_CONFIG, d_out=num_classes).cuda()\n",
    "model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0b9de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/6] Setting up W&B Logger...\n",
      "\n",
      "--- Weights & Biases (W&B) Configuration ---\n",
      "W&B username: tmpoulionis-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtmpoulionis\u001b[0m (\u001b[33mtmpoulionis-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B login successful!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb_logs/wandb/run-20251120_135441-n7xq75va</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tmpoulionis-/lightning_logs/runs/n7xq75va' target=\"_blank\">splendid-silence-44</a></strong> to <a href='https://wandb.ai/tmpoulionis-/lightning_logs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tmpoulionis-/lightning_logs' target=\"_blank\">https://wandb.ai/tmpoulionis-/lightning_logs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tmpoulionis-/lightning_logs/runs/n7xq75va' target=\"_blank\">https://wandb.ai/tmpoulionis-/lightning_logs/runs/n7xq75va</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Project: lightning_logs\n",
      "  ✓ Name: splendid-silence-44\n",
      "  ✓ URL: https://wandb.ai/tmpoulionis-/lightning_logs/runs/n7xq75va\n"
     ]
    }
   ],
   "source": [
    "# ------- W&B Logger -------\n",
    "print(\"\\n[3/6] Setting up W&B Logger...\")\n",
    "usrname = handle_wandb_login()\n",
    "wandb_logger = WandbLogger(\n",
    "    project=WANDB_CONFIG[\"project\"],\n",
    "    entity=usrname,\n",
    "    name=WANDB_CONFIG[\"name\"],\n",
    "    log_model=\"all\",\n",
    "    save_dir=\"./wandb_logs\"\n",
    ")\n",
    "\n",
    "print(f\"  ✓ Project:\", wandb_logger.experiment.project)\n",
    "print(f\"  ✓ Name:\", wandb_logger.experiment.name)\n",
    "print(f\"  ✓ URL:\", wandb_logger.experiment.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a51c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/6] Setting up Callbacks...\n",
      "  ✓ Learning rate monitor\n",
      "  ✓ Model checkpointing (save top 3)\n",
      "  ✓ Early stopping (patience=20)\n"
     ]
    }
   ],
   "source": [
    "# ------- Callbacks -------\n",
    "print(\"\\n[4/6] Setting up Callbacks...\")\n",
    "\n",
    "callbacks = [\n",
    "    LearningRateMonitor(logging_interval='step'),\n",
    "    ModelCheckpoint(\n",
    "        dirpath=f\"./checkpoints/{wandb_logger.name}\",\n",
    "        filename=\"best-{epoch:02d}-{val/acc:.4f}\",\n",
    "        monitor=\"val/acc\",\n",
    "        mode=\"max\",\n",
    "        save_top_k=1,\n",
    "        save_last=True\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val/loss\",\n",
    "        patience=20,\n",
    "        mode=\"min\",\n",
    "        verbose=True\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"  ✓ Learning rate monitor\")\n",
    "print(f\"  ✓ Model checkpointing (save top 3)\")\n",
    "print(f\"  ✓ Early stopping (patience=20)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca97fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Scheduler -------\n",
    "from train import create_scheduler\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "scheduler_config = {\n",
    "    \"scheduler\": create_scheduler,\n",
    "    \"params\": {\n",
    "        \"total_steps\": total_steps,\n",
    "        \"warmup_steps\": warmup_steps\n",
    "    }\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf18a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/6) Setting up Lightning Module...\n"
     ]
    }
   ],
   "source": [
    "# ------- Lightning Module -------\n",
    "print(\"\\n[5/6) Setting up Lightning Module...\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "lightning_module = LightningMamba(\n",
    "    model=model,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    loss_fn=loss_fn,\n",
    "    opt_hyperparams=OPTIMIZER_CONFIG,\n",
    "    scheduler_config=scheduler_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72506922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/6] Initializing Trainer...\n",
      "  ✓ Max steps: 200000\n",
      "  ✓ Max epochs: 30\n",
      "  ✓ Accelerator: auto\n",
      "  ✓ Gradient clip: 0.1\n"
     ]
    }
   ],
   "source": [
    "# ------- Trainer -------\n",
    "print(\"\\n[6/6] Initializing Trainer...\")\n",
    "trainer = L.Trainer(\n",
    "    **TRAINER_CONFIG,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "print(f\"  ✓ Max steps: {TRAINER_CONFIG['max_steps'] if TRAINER_CONFIG['max_steps'] else 'N/A'}\")\n",
    "print(f\"  ✓ Max epochs: {TRAINER_CONFIG['max_epochs'] if TRAINER_CONFIG['max_epochs'] else 'N/A'}\")\n",
    "print(f\"  ✓ Accelerator: {TRAINER_CONFIG['accelerator']}\")\n",
    "print(f\"  ✓ Gradient clip: {TRAINER_CONFIG['gradient_clip_val']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2690f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-20 17:03:41--  https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/p14/hg38.p14.fa.gz\n",
      "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
      "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1012013082 (965M) [application/x-gzip]\n",
      "Saving to: ‘hg38.p14.fa.gz’\n",
      "\n",
      "hg38.p14.fa.gz      100%[===================>] 965,13M  16,4MB/s    in 60s     \n",
      "\n",
      "2025-11-20 17:04:42 (16,1 MB/s) - ‘hg38.p14.fa.gz’ saved [1012013082/1012013082]\n",
      "\n",
      "rm: cannot remove 'hg38.p14.gz': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/p14/hg38.p14.fa.gz\n",
    "!gunzip hg38.p14.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c386ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[19ANNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNplace   \u001b[7m^U\u001b[m Paste Text\u001b[7m^T\u001b[m To Spell  \u001b[7m^_\u001b[m Go To Linenes ]\u001b[m\u001b[H\u001b[7m  GNU nano 4.8                      hg38.p14.fa                                 \u001b[1;79H\u001b[m\u001b[22;9H\u001b[7m[ line 1/65985253 (0%), col 1/6 (16%), char 0/3365209190 (0%) ]\u001b[m"
     ]
    }
   ],
   "source": [
    "!nano hg38.p14.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac540340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfaidx import Fasta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16faeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = Fasta(\"hg38.p14.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d528fb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['chr1', 'chr10', 'chr11', 'chr11_KI270721v1_random', 'chr12', 'chr13', 'chr14', 'chr14_GL000009v2_random', 'chr14_GL000225v1_random', 'chr14_KI270722v1_random', 'chr14_GL000194v1_random', 'chr14_KI270723v1_random', 'chr14_KI270724v1_random', 'chr14_KI270725v1_random', 'chr14_KI270726v1_random', 'chr15', 'chr15_KI270727v1_random', 'chr16', 'chr16_KI270728v1_random', 'chr17', 'chr17_GL000205v2_random', 'chr17_KI270729v1_random', 'chr17_KI270730v1_random', 'chr18', 'chr19', 'chr1_KI270706v1_random', 'chr1_KI270707v1_random', 'chr1_KI270708v1_random', 'chr1_KI270709v1_random', 'chr1_KI270710v1_random', 'chr1_KI270711v1_random', 'chr1_KI270712v1_random', 'chr1_KI270713v1_random', 'chr1_KI270714v1_random', 'chr2', 'chr20', 'chr21', 'chr22', 'chr22_KI270731v1_random', 'chr22_KI270732v1_random', 'chr22_KI270733v1_random', 'chr22_KI270734v1_random', 'chr22_KI270735v1_random', 'chr22_KI270736v1_random', 'chr22_KI270737v1_random', 'chr22_KI270738v1_random', 'chr22_KI270739v1_random', 'chr2_KI270715v1_random', 'chr2_KI270716v1_random', 'chr3', 'chr3_GL000221v1_random', 'chr4', 'chr4_GL000008v2_random', 'chr5', 'chr5_GL000208v1_random', 'chr6', 'chr7', 'chr8', 'chr9', 'chr9_KI270717v1_random', 'chr9_KI270718v1_random', 'chr9_KI270719v1_random', 'chr9_KI270720v1_random', 'chr1_KI270762v1_alt', 'chr1_KI270766v1_alt', 'chr1_KI270760v1_alt', 'chr1_KI270765v1_alt', 'chr1_GL383518v1_alt', 'chr1_GL383519v1_alt', 'chr1_GL383520v2_alt', 'chr1_KI270764v1_alt', 'chr1_KI270763v1_alt', 'chr1_KI270759v1_alt', 'chr1_KI270761v1_alt', 'chr2_KI270770v1_alt', 'chr2_KI270773v1_alt', 'chr2_KI270774v1_alt', 'chr2_KI270769v1_alt', 'chr2_GL383521v1_alt', 'chr2_KI270772v1_alt', 'chr2_KI270775v1_alt', 'chr2_KI270771v1_alt', 'chr2_KI270768v1_alt', 'chr2_GL582966v2_alt', 'chr2_GL383522v1_alt', 'chr2_KI270776v1_alt', 'chr2_KI270767v1_alt', 'chr3_JH636055v2_alt', 'chr3_KI270783v1_alt', 'chr3_KI270780v1_alt', 'chr3_GL383526v1_alt', 'chr3_KI270777v1_alt', 'chr3_KI270778v1_alt', 'chr3_KI270781v1_alt', 'chr3_KI270779v1_alt', 'chr3_KI270782v1_alt', 'chr3_KI270784v1_alt', 'chr4_KI270790v1_alt', 'chr4_GL383528v1_alt', 'chr4_KI270787v1_alt', 'chr4_GL000257v2_alt', 'chr4_KI270788v1_alt', 'chr4_GL383527v1_alt', 'chr4_KI270785v1_alt', 'chr4_KI270789v1_alt', 'chr4_KI270786v1_alt', 'chr5_KI270793v1_alt', 'chr5_KI270792v1_alt', 'chr5_KI270791v1_alt', 'chr5_GL383532v1_alt', 'chr5_GL949742v1_alt', 'chr5_KI270794v1_alt', 'chr5_GL339449v2_alt', 'chr5_GL383530v1_alt', 'chr5_KI270796v1_alt', 'chr5_GL383531v1_alt', 'chr5_KI270795v1_alt', 'chr6_GL000250v2_alt', 'chr6_KI270800v1_alt', 'chr6_KI270799v1_alt', 'chr6_GL383533v1_alt', 'chr6_KI270801v1_alt', 'chr6_KI270802v1_alt', 'chr6_KB021644v2_alt', 'chr6_KI270797v1_alt', 'chr6_KI270798v1_alt', 'chr7_KI270804v1_alt', 'chr7_KI270809v1_alt', 'chr7_KI270806v1_alt', 'chr7_GL383534v2_alt', 'chr7_KI270803v1_alt', 'chr7_KI270808v1_alt', 'chr7_KI270807v1_alt', 'chr7_KI270805v1_alt', 'chr8_KI270818v1_alt', 'chr8_KI270812v1_alt', 'chr8_KI270811v1_alt', 'chr8_KI270821v1_alt', 'chr8_KI270813v1_alt', 'chr8_KI270822v1_alt', 'chr8_KI270814v1_alt', 'chr8_KI270810v1_alt', 'chr8_KI270819v1_alt', 'chr8_KI270820v1_alt', 'chr8_KI270817v1_alt', 'chr8_KI270816v1_alt', 'chr8_KI270815v1_alt', 'chr9_GL383539v1_alt', 'chr9_GL383540v1_alt', 'chr9_GL383541v1_alt', 'chr9_GL383542v1_alt', 'chr9_KI270823v1_alt', 'chr10_GL383545v1_alt', 'chr10_KI270824v1_alt', 'chr10_GL383546v1_alt', 'chr10_KI270825v1_alt', 'chr11_KI270832v1_alt', 'chr11_KI270830v1_alt', 'chr11_KI270831v1_alt', 'chr11_KI270829v1_alt', 'chr11_GL383547v1_alt', 'chr11_JH159136v1_alt', 'chr11_JH159137v1_alt', 'chr11_KI270827v1_alt', 'chr11_KI270826v1_alt', 'chr12_GL877875v1_alt', 'chr12_GL877876v1_alt', 'chr12_KI270837v1_alt', 'chr12_GL383549v1_alt', 'chr12_KI270835v1_alt', 'chr12_GL383550v2_alt', 'chr12_GL383552v1_alt', 'chr12_GL383553v2_alt', 'chr12_KI270834v1_alt', 'chr12_GL383551v1_alt', 'chr12_KI270833v1_alt', 'chr12_KI270836v1_alt', 'chr13_KI270840v1_alt', 'chr13_KI270839v1_alt', 'chr13_KI270843v1_alt', 'chr13_KI270841v1_alt', 'chr13_KI270838v1_alt', 'chr13_KI270842v1_alt', 'chr14_KI270844v1_alt', 'chr14_KI270847v1_alt', 'chr14_KI270845v1_alt', 'chr14_KI270846v1_alt', 'chr15_KI270852v1_alt', 'chr15_KI270851v1_alt', 'chr15_KI270848v1_alt', 'chr15_GL383554v1_alt', 'chr15_KI270849v1_alt', 'chr15_GL383555v2_alt', 'chr15_KI270850v1_alt', 'chr16_KI270854v1_alt', 'chr16_KI270856v1_alt', 'chr16_KI270855v1_alt', 'chr16_KI270853v1_alt', 'chr16_GL383556v1_alt', 'chr16_GL383557v1_alt', 'chr17_GL383563v3_alt', 'chr17_KI270862v1_alt', 'chr17_KI270861v1_alt', 'chr17_KI270857v1_alt', 'chr17_JH159146v1_alt', 'chr17_JH159147v1_alt', 'chr17_GL383564v2_alt', 'chr17_GL000258v2_alt', 'chr17_GL383565v1_alt', 'chr17_KI270858v1_alt', 'chr17_KI270859v1_alt', 'chr17_GL383566v1_alt', 'chr17_KI270860v1_alt', 'chr18_KI270864v1_alt', 'chr18_GL383567v1_alt', 'chr18_GL383570v1_alt', 'chr18_GL383571v1_alt', 'chr18_GL383568v1_alt', 'chr18_GL383569v1_alt', 'chr18_GL383572v1_alt', 'chr18_KI270863v1_alt', 'chr19_KI270868v1_alt', 'chr19_KI270865v1_alt', 'chr19_GL383573v1_alt', 'chr19_GL383575v2_alt', 'chr19_GL383576v1_alt', 'chr19_GL383574v1_alt', 'chr19_KI270866v1_alt', 'chr19_KI270867v1_alt', 'chr19_GL949746v1_alt', 'chr20_GL383577v2_alt', 'chr20_KI270869v1_alt', 'chr20_KI270871v1_alt', 'chr20_KI270870v1_alt', 'chr21_GL383578v2_alt', 'chr21_KI270874v1_alt', 'chr21_KI270873v1_alt', 'chr21_GL383579v2_alt', 'chr21_GL383580v2_alt', 'chr21_GL383581v2_alt', 'chr21_KI270872v1_alt', 'chr22_KI270875v1_alt', 'chr22_KI270878v1_alt', 'chr22_KI270879v1_alt', 'chr22_KI270876v1_alt', 'chr22_KI270877v1_alt', 'chr22_GL383583v2_alt', 'chr22_GL383582v2_alt', 'chrX_KI270880v1_alt', 'chrX_KI270881v1_alt', 'chr19_KI270882v1_alt', 'chr19_KI270883v1_alt', 'chr19_KI270884v1_alt', 'chr19_KI270885v1_alt', 'chr19_KI270886v1_alt', 'chr19_KI270887v1_alt', 'chr19_KI270888v1_alt', 'chr19_KI270889v1_alt', 'chr19_KI270890v1_alt', 'chr19_KI270891v1_alt', 'chr1_KI270892v1_alt', 'chr2_KI270894v1_alt', 'chr2_KI270893v1_alt', 'chr3_KI270895v1_alt', 'chr4_KI270896v1_alt', 'chr5_KI270897v1_alt', 'chr5_KI270898v1_alt', 'chr6_GL000251v2_alt', 'chr7_KI270899v1_alt', 'chr8_KI270901v1_alt', 'chr8_KI270900v1_alt', 'chr11_KI270902v1_alt', 'chr11_KI270903v1_alt', 'chr12_KI270904v1_alt', 'chr15_KI270906v1_alt', 'chr15_KI270905v1_alt', 'chr17_KI270907v1_alt', 'chr17_KI270910v1_alt', 'chr17_KI270909v1_alt', 'chr17_JH159148v1_alt', 'chr17_KI270908v1_alt', 'chr18_KI270912v1_alt', 'chr18_KI270911v1_alt', 'chr19_GL949747v2_alt', 'chr22_KB663609v1_alt', 'chrX_KI270913v1_alt', 'chr19_KI270914v1_alt', 'chr19_KI270915v1_alt', 'chr19_KI270916v1_alt', 'chr19_KI270917v1_alt', 'chr19_KI270918v1_alt', 'chr19_KI270919v1_alt', 'chr19_KI270920v1_alt', 'chr19_KI270921v1_alt', 'chr19_KI270922v1_alt', 'chr19_KI270923v1_alt', 'chr3_KI270924v1_alt', 'chr4_KI270925v1_alt', 'chr6_GL000252v2_alt', 'chr8_KI270926v1_alt', 'chr11_KI270927v1_alt', 'chr19_GL949748v2_alt', 'chr22_KI270928v1_alt', 'chr19_KI270929v1_alt', 'chr19_KI270930v1_alt', 'chr19_KI270931v1_alt', 'chr19_KI270932v1_alt', 'chr19_KI270933v1_alt', 'chr19_GL000209v2_alt', 'chr3_KI270934v1_alt', 'chr6_GL000253v2_alt', 'chr19_GL949749v2_alt', 'chr3_KI270935v1_alt', 'chr6_GL000254v2_alt', 'chr19_GL949750v2_alt', 'chr3_KI270936v1_alt', 'chr6_GL000255v2_alt', 'chr19_GL949751v2_alt', 'chr3_KI270937v1_alt', 'chr6_GL000256v2_alt', 'chr19_GL949752v1_alt', 'chr6_KI270758v1_alt', 'chr19_GL949753v2_alt', 'chr19_KI270938v1_alt', 'chrM', 'chrUn_KI270302v1', 'chrUn_KI270304v1', 'chrUn_KI270303v1', 'chrUn_KI270305v1', 'chrUn_KI270322v1', 'chrUn_KI270320v1', 'chrUn_KI270310v1', 'chrUn_KI270316v1', 'chrUn_KI270315v1', 'chrUn_KI270312v1', 'chrUn_KI270311v1', 'chrUn_KI270317v1', 'chrUn_KI270412v1', 'chrUn_KI270411v1', 'chrUn_KI270414v1', 'chrUn_KI270419v1', 'chrUn_KI270418v1', 'chrUn_KI270420v1', 'chrUn_KI270424v1', 'chrUn_KI270417v1', 'chrUn_KI270422v1', 'chrUn_KI270423v1', 'chrUn_KI270425v1', 'chrUn_KI270429v1', 'chrUn_KI270442v1', 'chrUn_KI270466v1', 'chrUn_KI270465v1', 'chrUn_KI270467v1', 'chrUn_KI270435v1', 'chrUn_KI270438v1', 'chrUn_KI270468v1', 'chrUn_KI270510v1', 'chrUn_KI270509v1', 'chrUn_KI270518v1', 'chrUn_KI270508v1', 'chrUn_KI270516v1', 'chrUn_KI270512v1', 'chrUn_KI270519v1', 'chrUn_KI270522v1', 'chrUn_KI270511v1', 'chrUn_KI270515v1', 'chrUn_KI270507v1', 'chrUn_KI270517v1', 'chrUn_KI270529v1', 'chrUn_KI270528v1', 'chrUn_KI270530v1', 'chrUn_KI270539v1', 'chrUn_KI270538v1', 'chrUn_KI270544v1', 'chrUn_KI270548v1', 'chrUn_KI270583v1', 'chrUn_KI270587v1', 'chrUn_KI270580v1', 'chrUn_KI270581v1', 'chrUn_KI270579v1', 'chrUn_KI270589v1', 'chrUn_KI270590v1', 'chrUn_KI270584v1', 'chrUn_KI270582v1', 'chrUn_KI270588v1', 'chrUn_KI270593v1', 'chrUn_KI270591v1', 'chrUn_KI270330v1', 'chrUn_KI270329v1', 'chrUn_KI270334v1', 'chrUn_KI270333v1', 'chrUn_KI270335v1', 'chrUn_KI270338v1', 'chrUn_KI270340v1', 'chrUn_KI270336v1', 'chrUn_KI270337v1', 'chrUn_KI270363v1', 'chrUn_KI270364v1', 'chrUn_KI270362v1', 'chrUn_KI270366v1', 'chrUn_KI270378v1', 'chrUn_KI270379v1', 'chrUn_KI270389v1', 'chrUn_KI270390v1', 'chrUn_KI270387v1', 'chrUn_KI270395v1', 'chrUn_KI270396v1', 'chrUn_KI270388v1', 'chrUn_KI270394v1', 'chrUn_KI270386v1', 'chrUn_KI270391v1', 'chrUn_KI270383v1', 'chrUn_KI270393v1', 'chrUn_KI270384v1', 'chrUn_KI270392v1', 'chrUn_KI270381v1', 'chrUn_KI270385v1', 'chrUn_KI270382v1', 'chrUn_KI270376v1', 'chrUn_KI270374v1', 'chrUn_KI270372v1', 'chrUn_KI270373v1', 'chrUn_KI270375v1', 'chrUn_KI270371v1', 'chrUn_KI270448v1', 'chrUn_KI270521v1', 'chrUn_GL000195v1', 'chrUn_GL000219v1', 'chrUn_GL000220v1', 'chrUn_GL000224v1', 'chrUn_KI270741v1', 'chrUn_GL000226v1', 'chrUn_GL000213v1', 'chrUn_KI270743v1', 'chrUn_KI270744v1', 'chrUn_KI270745v1', 'chrUn_KI270746v1', 'chrUn_KI270747v1', 'chrUn_KI270748v1', 'chrUn_KI270749v1', 'chrUn_KI270750v1', 'chrUn_KI270751v1', 'chrUn_KI270752v1', 'chrUn_KI270753v1', 'chrUn_KI270754v1', 'chrUn_KI270755v1', 'chrUn_KI270756v1', 'chrUn_KI270757v1', 'chrUn_GL000214v1', 'chrUn_KI270742v1', 'chrUn_GL000216v2', 'chrUn_GL000218v1', 'chrX', 'chrY', 'chrY_KI270740v1_random', 'chr1_KQ031383v1_fix', 'chr1_KQ983255v1_alt', 'chr1_KN538361v1_fix', 'chr1_KQ458383v1_alt', 'chr1_KN196473v1_fix', 'chr1_KZ208904v1_alt', 'chr1_KN196472v1_fix', 'chr1_KZ208905v1_alt', 'chr1_KQ458382v1_alt', 'chr1_KV880763v1_alt', 'chr1_KN196474v1_fix', 'chr1_KN538360v1_fix', 'chr1_KZ208906v1_fix', 'chr1_KQ458384v1_alt', 'chr2_KQ031384v1_fix', 'chr2_KZ208907v1_alt', 'chr2_KQ983256v1_alt', 'chr2_KZ208908v1_alt', 'chr2_KN538363v1_fix', 'chr2_KN538362v1_fix', 'chr3_KV766192v1_fix', 'chr3_KN196475v1_fix', 'chr3_KQ031385v1_fix', 'chr3_KN538364v1_fix', 'chr3_KZ208909v1_alt', 'chr3_KQ031386v1_fix', 'chr3_KN196476v1_fix', 'chr4_KQ090013v1_alt', 'chr4_KQ090014v1_alt', 'chr4_KQ090015v1_alt', 'chr4_KV766193v1_alt', 'chr4_KQ983257v1_fix', 'chr4_KQ983258v1_alt', 'chr5_KZ208910v1_alt', 'chr5_KN196477v1_alt', 'chr5_KV575243v1_alt', 'chr5_KV575244v1_fix', 'chr6_KZ208911v1_fix', 'chr6_KQ090017v1_alt', 'chr6_KQ031387v1_fix', 'chr6_KN196478v1_fix', 'chr6_KQ090016v1_fix', 'chr6_KV766194v1_fix', 'chr7_KV880764v1_fix', 'chr7_KV880765v1_fix', 'chr7_KZ208912v1_fix', 'chr7_KZ208913v1_alt', 'chr7_KQ031388v1_fix', 'chr8_KZ208915v1_fix', 'chr8_KV880767v1_fix', 'chr8_KV880766v1_fix', 'chr8_KZ208914v1_fix', 'chr9_KQ090018v1_alt', 'chr9_KQ090019v1_alt', 'chr9_KN196479v1_fix', 'chr10_KN538367v1_fix', 'chr10_KQ090020v1_alt', 'chr10_KN196480v1_fix', 'chr10_KQ090021v1_fix', 'chr10_KN538366v1_fix', 'chr10_KN538365v1_fix', 'chr11_KQ759759v1_fix', 'chr11_KN538368v1_alt', 'chr11_KV766195v1_fix', 'chr11_KQ090022v1_fix', 'chr11_KN196481v1_fix', 'chr12_KQ090023v1_alt', 'chr12_KZ208916v1_fix', 'chr12_KN538369v1_fix', 'chr12_KN196482v1_fix', 'chr12_KZ208918v1_alt', 'chr12_KQ759760v1_fix', 'chr12_KZ208917v1_fix', 'chr12_KN538370v1_fix', 'chr13_KN538372v1_fix', 'chr13_KQ090024v1_alt', 'chr13_KN196483v1_fix', 'chr13_KN538373v1_fix', 'chr13_KQ090025v1_alt', 'chr13_KN538371v1_fix', 'chr14_KZ208920v1_fix', 'chr14_KZ208919v1_alt', 'chr15_KN538374v1_fix', 'chr15_KQ031389v1_alt', 'chr16_KQ090026v1_alt', 'chr16_KV880768v1_fix', 'chr16_KQ090027v1_alt', 'chr16_KZ208921v1_alt', 'chr16_KQ031390v1_alt', 'chr17_KV766196v1_fix', 'chr17_KV575245v1_fix', 'chr17_KV766198v1_alt', 'chr17_KV766197v1_alt', 'chr18_KQ458385v1_alt', 'chr18_KQ090028v1_fix', 'chr18_KZ208922v1_fix', 'chr19_KQ458386v1_fix', 'chr19_KN196484v1_fix', 'chr19_KV575246v1_alt', 'chr19_KV575247v1_alt', 'chr19_KV575248v1_alt', 'chr19_KV575249v1_alt', 'chr19_KV575250v1_alt', 'chr19_KV575251v1_alt', 'chr19_KV575252v1_alt', 'chr19_KV575253v1_alt', 'chr19_KV575254v1_alt', 'chr19_KV575255v1_alt', 'chr19_KV575256v1_alt', 'chr19_KV575257v1_alt', 'chr19_KV575259v1_alt', 'chr19_KV575260v1_alt', 'chr19_KV575258v1_alt', 'chr22_KN196485v1_alt', 'chr22_KQ458387v1_alt', 'chr22_KQ458388v1_alt', 'chr22_KN196486v1_alt', 'chr22_KQ759761v1_alt', 'chr22_KQ759762v1_fix', 'chrX_KV766199v1_alt', 'chrY_KZ208923v1_fix', 'chrY_KZ208924v1_fix', 'chrY_KN196487v1_fix', 'chr1_KZ559100v1_fix', 'chr3_KZ559104v1_fix', 'chr3_KZ559105v1_alt', 'chr3_KZ559103v1_alt', 'chr3_KZ559102v1_alt', 'chr3_KZ559101v1_alt', 'chr7_KZ559106v1_alt', 'chr8_KZ559107v1_alt', 'chr11_KZ559109v1_fix', 'chr11_KZ559108v1_fix', 'chr11_KZ559111v1_alt', 'chr11_KZ559110v1_alt', 'chr12_KZ559112v1_alt', 'chr16_KZ559113v1_fix', 'chr17_KZ559114v1_alt', 'chr18_KZ559116v1_alt', 'chr18_KZ559115v1_fix', 'chr2_ML143342v1_fix', 'chr2_ML143341v1_fix', 'chr3_ML143343v1_alt', 'chr4_ML143344v1_fix', 'chr4_ML143347v1_fix', 'chr4_ML143346v1_fix', 'chr4_ML143348v1_fix', 'chr4_ML143345v1_fix', 'chr4_ML143349v1_fix', 'chr5_ML143350v1_fix', 'chr6_ML143351v1_fix', 'chr7_ML143352v1_fix', 'chr9_ML143353v1_fix', 'chr10_ML143354v1_fix', 'chr10_ML143355v1_fix', 'chr11_ML143358v1_fix', 'chr11_ML143360v1_fix', 'chr11_ML143359v1_fix', 'chr11_ML143357v1_fix', 'chr11_ML143356v1_fix', 'chr12_ML143362v1_fix', 'chr12_ML143361v1_fix', 'chr13_ML143366v1_fix', 'chr13_ML143363v1_fix', 'chr13_ML143364v1_fix', 'chr13_ML143365v1_fix', 'chr14_ML143367v1_fix', 'chr14_ML143368v1_alt', 'chr15_ML143372v1_fix', 'chr15_ML143371v1_fix', 'chr15_ML143370v1_fix', 'chr15_ML143369v1_fix', 'chr16_ML143373v1_fix', 'chr17_ML143374v1_fix', 'chr17_ML143375v1_fix', 'chr19_ML143376v1_fix', 'chr21_ML143377v1_fix', 'chr22_ML143380v1_fix', 'chr22_ML143378v1_fix', 'chr22_ML143379v1_fix', 'chrX_ML143385v1_fix', 'chrX_ML143382v1_fix', 'chrX_ML143383v1_fix', 'chrX_ML143381v1_fix', 'chrX_ML143384v1_fix', 'chr1_MU273333v1_fix', 'chr1_MU273330v1_alt', 'chr1_MU273335v1_fix', 'chr1_MU273336v1_fix', 'chr1_MU273331v1_alt', 'chr1_MU273334v1_fix', 'chr1_MU273332v1_alt', 'chr2_MU273344v1_fix', 'chr2_MU273345v1_fix', 'chr2_MU273343v1_fix', 'chr2_MU273340v1_alt', 'chr2_MU273337v1_alt', 'chr2_MU273342v1_fix', 'chr2_MU273339v1_alt', 'chr2_MU273338v1_alt', 'chr2_MU273341v1_fix', 'chr3_MU273347v1_fix', 'chr3_MU273348v1_fix', 'chr3_MU273346v1_fix', 'chr4_MU273351v1_fix', 'chr4_MU273349v1_alt', 'chr4_MU273350v1_fix', 'chr5_MU273354v1_fix', 'chr5_MU273353v1_fix', 'chr5_MU273356v1_alt', 'chr5_MU273355v1_fix', 'chr5_MU273352v1_fix', 'chr6_MU273357v1_alt', 'chr7_MU273358v1_alt', 'chr8_MU273362v1_fix', 'chr8_MU273359v1_fix', 'chr8_MU273361v1_fix', 'chr8_MU273363v1_fix', 'chr8_MU273360v1_fix', 'chr9_MU273366v1_fix', 'chr9_MU273364v1_fix', 'chr9_MU273365v1_fix', 'chr10_MU273367v1_fix', 'chr11_KQ759759v2_fix', 'chr11_MU273369v1_fix', 'chr11_MU273371v1_fix', 'chr11_MU273370v1_fix', 'chr11_MU273368v1_alt', 'chr12_MU273372v1_fix', 'chr14_MU273373v1_fix', 'chr15_MU273375v1_alt', 'chr15_MU273374v1_fix', 'chr16_MU273376v1_fix', 'chr16_MU273377v1_fix', 'chr17_MU273380v1_fix', 'chr17_MU273378v1_alt', 'chr17_MU273383v1_fix', 'chr17_MU273379v1_fix', 'chr17_MU273382v1_fix', 'chr17_MU273381v1_fix', 'chr19_MU273386v1_fix', 'chr19_MU273387v1_alt', 'chr19_MU273384v1_fix', 'chr19_MU273385v1_fix', 'chr20_MU273388v1_fix', 'chr20_MU273389v1_fix', 'chr21_MU273390v1_fix', 'chr21_MU273391v1_fix', 'chr21_MU273392v1_fix', 'chr22_KQ759762v2_fix', 'chrX_MU273397v1_alt', 'chrX_MU273393v1_fix', 'chrX_MU273394v1_fix', 'chrX_MU273396v1_alt', 'chrX_MU273395v1_alt', 'chrY_MU273398v1_fix'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasta.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc64345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ">chr1:1-100\n",
       "NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasta['chr1'][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4254a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  839M  100  839M    0     0  11.2M      0  0:01:14  0:01:14 --:--:-- 11.6M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1112k  100 1112k    0     0   854k      0  0:00:01  0:00:01 --:--:--  854k\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data/hg38/\n",
    "!curl https://storage.googleapis.com/basenji_barnyard2/hg38.ml.fa.gz > data/hg38/hg38.ml.fa.gz\n",
    "!curl https://storage.googleapis.com/basenji_barnyard2/sequences_human.bed > data/hg38/human-sequences.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeb18c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip data/hg38/hg38.ml.fa.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3238906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/tmpoulionis/miniconda3/envs/mamba/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataloaders.datasets.hg38_dataset import HG38Dataset\n",
    "from dataloaders.datasets.hg38_char_tokenizer import CharacterTokenizer\n",
    "\n",
    "seqlen = 2**17\n",
    "bed_file_path = 'data/hg38/human-sequences.bed'\n",
    "fasta_file_path = 'data/hg38/hg38.ml.fa'\n",
    "chars = ['A', 'T', 'C', 'G', 'N', 'a', 't', 'c', 'g', 'n', '.']\n",
    "\n",
    "tokenizer = CharacterTokenizer(\n",
    "    characters=chars,\n",
    "    model_max_length=seqlen\n",
    ")\n",
    "\n",
    "data = HG38Dataset(\n",
    "    split='train',\n",
    "    bed_file=bed_file_path,\n",
    "    fasta_file=fasta_file_path,\n",
    "    max_length=seqlen,\n",
    "    tokenizer_name='char',\n",
    "    tokenizer=tokenizer,\n",
    "    add_eos=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03777aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34021"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee5e0eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/tmpoulionis/nn_mamba/dataloaders/datasets/hg38_dataset.py:187: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  chr_name, start, end = (row[0], row[1], row[2])\n"
     ]
    }
   ],
   "source": [
    "input, target = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8d04efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 10, 10,  ...,  7,  7,  7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7047648c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131071"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5622e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131071"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2217d0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/tmpoulionis/nn_mamba/dataloaders/datasets/hg38_dataset.py:187: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  chr_name, start, end = (row[0], row[1], row[2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 8,  7, 10,  ..., 10,  7, 10]),\n",
       " tensor([ 7, 10,  9,  ...,  7, 10,  1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1369e2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8,  7, 10,  9,  7,  8,  7,  8,  8,  7, 10,  9,  7,  8,  8,  8,  8,  7,\n",
      "         8, 10])\n",
      "tensor([ 7, 10,  9,  7,  8,  7,  8,  8,  7, 10,  9,  7,  8,  8,  8,  8,  7,  8,\n",
      "        10,  8])\n"
     ]
    }
   ],
   "source": [
    "print(data[1][0][0:20])\n",
    "print(data[1][1][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5ddbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
